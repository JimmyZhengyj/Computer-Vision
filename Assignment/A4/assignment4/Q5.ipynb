{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "from PIL import Image\n",
    "import numpy.linalg as linalg\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iou(boxA, boxB):\n",
    "    \"\"\"\n",
    "    Get the IoU between two rectangles.\n",
    "    \"\"\"\n",
    "    \n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "\n",
    "    intersect_Area = abs(xB - xA) * abs(yB - yA)\n",
    "\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    \n",
    "    iou = intersect_Area / float(boxAArea + boxBArea - intersect_Area)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[329  72 110 110]]\n",
      "roi (110, 110, 3)\n",
      "hsv_roi (110, 110, 3)\n",
      "mask (110, 110)\n",
      "roi_hist (180, 1)\n",
      "ite  26  len:  2\n",
      "ite  30  len:  2\n",
      "ite  31  len:  2\n",
      "ite  32  len:  2\n",
      "ite  33  len:  2\n",
      "ite  43  len:  2\n",
      "ite  44  len:  2\n",
      "ite  46  len:  2\n",
      "ite  49  len:  2\n",
      "ite  50  len:  2\n",
      "ite  51  len:  2\n",
      "ite  53  len:  2\n",
      "ite  54  len:  2\n",
      "ite  64  len:  2\n",
      "ite  67  len:  2\n",
      "ite  68  len:  3\n",
      "ite  70  len:  2\n",
      "ite  71  len:  2\n",
      "ite  72  len:  2\n",
      "ite  73  len:  2\n",
      "ite  74  len:  2\n",
      "ite  75  len:  2\n",
      "ite  80  len:  2\n",
      "ite  81  len:  2\n",
      "ite  85  len:  2\n",
      "ite  86  len:  2\n",
      "ite  91  len:  2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_video_path = 'KylianMbappe.mp4'\n",
    "# input_video_path = 'zoom_2.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path) # read mp4\n",
    "\n",
    "# capture one frame\n",
    "ret,frame = cap.read()\n",
    "\n",
    "# detect a face on the first frame\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') \n",
    "face_boxes = face_detector.detectMultiScale(frame) \n",
    "print(face_boxes)\n",
    "\n",
    "if len(face_boxes)==0:\n",
    "    print('no face detected')\n",
    "    assert(False)\n",
    "\n",
    "# initialize the tracing window around the (first) detected face\n",
    "(x,y,w,h) = tuple(face_boxes[0]) \n",
    "track_window = (x,y,w,h)\n",
    "\n",
    "#  region of interest for tracking\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "print(\"roi\", roi.shape)\n",
    "\n",
    "# convert the roi to HSV so we can construct a histogram of Hue \n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "print(\"hsv_roi\", hsv_roi.shape)\n",
    "\n",
    "# why do we need this mask? (remember the cone?)\n",
    "# read the description for Figure 3 in the original Cam Shift paper: http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.14.7673 \n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "print(\"mask\",mask.shape)\n",
    "\n",
    "\n",
    "# form histogram of hue in the roi\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "print(\"roi_hist\", roi_hist.shape)\n",
    "\n",
    "# normalize the histogram array values so they are in the min=0 to max=255 range\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# termination criteria for mean shift: 10 iteration or shift less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "IoU_list = []\n",
    "keep_img = []\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    count += 1\n",
    "    \n",
    "    # grab a frame\n",
    "    ret ,frame = cap.read() \n",
    "    \n",
    "    if ret == True: \n",
    "  \n",
    "        # convert to HSV\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # histogram back projection using roi_hist \n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "        \n",
    "        # use meanshift to shift the tracking window\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "        \n",
    "        # display tracked window\n",
    "        x1,y1,w1,h1 = track_window\n",
    "        img = cv2.rectangle(frame, (x1,y1), (x1+w1,y1+h1), (0,0,255),5)\n",
    "        \n",
    "        # default detector\n",
    "        temp_face_boxes = face_detector.detectMultiScale(frame)\n",
    "        if len(temp_face_boxes)> 1:\n",
    "            print(\"ite \", count, \" len: \", len(temp_face_boxes))\n",
    "            for temp_face in temp_face_boxes:\n",
    "                (x2,y2,w2,h2) = tuple(temp_face_boxes[0]) \n",
    "                temp_track_window = (x2,y2,w2,h2)\n",
    "                img = cv2.rectangle(frame, (x2,y2), (x2+w2,y2+h2), (0,255,0),5)\n",
    "                \n",
    "                box_tracked = [x1, y1, x1+w1, y1+h1]\n",
    "                box_bounded = [x2, y2, x2+w2, y2+h2]\n",
    "                IoU = get_iou(box_tracked, box_bounded)\n",
    "            IoU_list.append(IoU)\n",
    "        \n",
    "        if IoU > 0.73:\n",
    "            keep_img.append(img)\n",
    "        \n",
    "        cv2.imshow('mean shift tracking demo',img)\n",
    "        \n",
    "        if cv2.waitKey(33) & 0xFF == 27: # wait a bit and exit is ESC is pressed\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7356562745611737\n",
      "4\n",
      "0.052083333333333336\n"
     ]
    }
   ],
   "source": [
    "n = len(IoU_list)\n",
    "print(max(IoU_list))\n",
    "print(len(keep_img))\n",
    "\n",
    "m = 0\n",
    "for item in IoU_list:\n",
    "    if item > 0.7:\n",
    "        m+= 1\n",
    "print(m/n)\n",
    "\n",
    "# plot sample image\n",
    "\n",
    "cv2.imshow(\"image with low IoU\", keep_img[0])\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# plt.plot(list(range(2,n+2)), IoU_list)\n",
    "# plt.xlabel(\"time\")\n",
    "# plt.ylabel(\"IoU\")\n",
    "# plt.title(\"IoU curve under method of gradient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = 'KylianMbappe.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path) # read mp4\n",
    "\n",
    "# capture one frame\n",
    "ret,frame = cap.read()\n",
    "\n",
    "# detect a face on the first frame\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml') \n",
    "face_boxes = face_detector.detectMultiScale(frame) \n",
    "\n",
    "if len(face_boxes)==0:\n",
    "    print('no face detected')\n",
    "    assert(False)\n",
    "\n",
    "# initialize the tracing window around the (first) detected face\n",
    "(x,y,w,h) = tuple(face_boxes[0]) \n",
    "track_window = (x,y,w,h)\n",
    "\n",
    "#  region of interest for tracking\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "# convert the roi to gray so we can construct a histogram of Hue \n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "Ix = cv2.Sobel(hsv_roi, cv2.CV_64F, 1,0, ksize = 5)\n",
    "Iy = cv2.Sobel(hsv_roi, cv2.CV_64F, 0,1, ksize = 5)\n",
    "\n",
    "mag, ang = cv2.cartToPolar(Ix,Iy,angleInDegrees=True)\n",
    "ang = np.array([ang], dtype=np.uint8)\n",
    "\n",
    "mask = cv2.inRange(mag, np.array([np.max(mag)/10]), np.array([np.max(mag)]))\n",
    "\n",
    "# # form histogram of hue in the roi\n",
    "# roi_hist = cv2.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "roi_hist = cv2.calcHist(ang,[0],mask,[24],[0,360])\n",
    "\n",
    "# normalize the histogram array values so they are in the min=0 to max=360 range\n",
    "cv2.normalize(roi_hist,roi_hist,0,360,cv2.NORM_MINMAX)\n",
    "\n",
    "# termination criteria for mean shift: 10 iteration or shift less than 1 pixel\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "IoU_list = []\n",
    "keep_img = []\n",
    "\n",
    "box_bounded = [x,y,x+w, y+h]\n",
    "\n",
    "while True:\n",
    "    \n",
    "    # grab a frame\n",
    "    ret ,frame = cap.read() \n",
    "    \n",
    "    if ret == True: \n",
    "  \n",
    "        # convert to HSV\n",
    "        gray_image = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV) \n",
    "        \n",
    "        # histogram back projection using roi_hist \n",
    "        dst = cv2.calcBackProject([gray_image],[0],roi_hist,[0,360],1)\n",
    "        \n",
    "        # use meanshift to shift the tracking window\n",
    "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "        \n",
    "        frame2 = deepcopy(frame)\n",
    "        \n",
    "        # display tracked window\n",
    "        x1,y1,w1,h1 = track_window\n",
    "        img = cv2.rectangle(frame, (x1,y1), (x1+w1,y1+h1), (0,0,255),5)\n",
    "\n",
    "        # default detector\n",
    "        temp_face_boxes = face_detector.detectMultiScale(frame)\n",
    "        \n",
    "        find_max = -1\n",
    "        box_tracked = [x1, y1, x1+w1, y1+h1]\n",
    "        box_bounded_final = temp_face_boxes[0]\n",
    "        for temp_face in temp_face_boxes:\n",
    "            (x2,y2,w2,h2) = tuple(temp_face) \n",
    "            box_bounded_temp = [x2, y2, x2+w2, y2+h2]\n",
    "            if get_iou(box_bounded_temp, box_bounded)> find_max:\n",
    "                box_bounded_final = box_bounded_temp\n",
    "                find_max = get_iou(box_bounded_temp, box_bounded)\n",
    "        img = cv2.rectangle(frame, (box_bounded_final[0],box_bounded_final[1]), (box_bounded_final[2],box_bounded_final[3]), (0,255,0),5)\n",
    "        \n",
    "        box_bounded = box_bounded_final\n",
    "        IoU = get_iou(box_tracked, box_bounded)\n",
    "        IoU_list.append(IoU)\n",
    "        \n",
    "        if IoU < 0.57:\n",
    "            keep_img.append(img)\n",
    "        \n",
    "        cv2.imshow('mean shift tracking demo',img)\n",
    "        \n",
    "        if cv2.waitKey(33) & 0xFF == 27: # wait a bit and exit is ESC is pressed\n",
    "            break\n",
    "        \n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a17d887aaecf5c6664e30a794016285c941788257519da7555f342fc959ca9d6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
